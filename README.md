# Data_Analysis
## Approach to the Solution:

# 1)Data Extraction:

Utilized Python programming in a Google Colab notebook.
Employed BeautifulSoup library for web scraping within the Colab environment.
Extracted article title and text from the provided URLs while excluding any extraneous content like website headers or footers.
Saved the extracted article text in text files named after their respective URL_IDs within the Colab environment.


# 2)Data Analysis:

Utilized Python programming within the Colab notebook for text analysis.
Leveraged NLTK library for natural language processing directly within the Colab environment.
Computed variables such as POSITIVE SCORE, NEGATIVE SCORE, POLARITY SCORE, etc., as outlined in the provided "Text Analysis.docx" file.
Ensured the computed variables matched the order specified in the "Output Data Structure.xlsx" file.

# Running the .ipynb File to Generate Output:

# 1)Opening the Notebook:

Open the provided Google Colab notebook (.ipynb file) in Google Colab.

# 2)Dependencies:

No installation of dependencies required as Google Colab already provides necessary libraries like BeautifulSoup and NLTK.
Ensure the notebook has internet connectivity for web scraping purposes.

# 3)Execution:

Execute the cells within the Colab notebook one by one.
The notebook will automatically extract data from the URLs, perform text analysis, and generate the output in the specified format.

Note:

Ensure that the notebook has access to the provided input file "Input.xlsx" containing the URLs of the articles and the other needed files used in the program.
